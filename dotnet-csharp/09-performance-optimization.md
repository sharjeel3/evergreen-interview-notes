# Performance Optimization

**Level:** üî• Advanced  
**Tags:** `performance`, `optimization`, `benchmarking`, `Span<T>`, `interview`

---

## Why this matters

Performance optimization is **what separates engineers who ship features from those who ship features that scale to millions of users**. It's about making the same hardware serve 10x more traffic, or reducing cloud costs by 80%, or making applications responsive enough that users actually enjoy them.

**The business impact of performance:** Performance directly affects the bottom line:
- **Amazon:** 100ms latency costs 1% of sales
- **Google:** 500ms slowdown reduces traffic by 20%
- **User retention:** 40% of users abandon sites that take >3s to load
- **Cloud costs:** 2x performance improvement = 50% reduction in server costs
- **Competitive advantage:** Fast apps win market share from slow competitors

I've seen companies reduce their AWS bills from $500K/year to $100K/year through performance optimization‚Äîthat's real money that could fund entire teams.

**When performance matters most:**
- **High-throughput APIs:** Serving 100K+ requests/second requires every optimization
- **Real-time systems:** Gaming, trading, IoT need <10ms response times
- **Mobile applications:** Battery life and bandwidth constraints demand efficiency
- **Cost-sensitive systems:** Startups need to do more with limited infrastructure
- **User-facing applications:** Every 100ms of latency costs user satisfaction

**The modern performance toolkit:** .NET has evolved dramatically for performance:

**`Span<T>` and `Memory<T>`:** These types enable zero-allocation string parsing, array manipulation, and buffer operations. I've seen systems go from processing 10K messages/sec to 100K messages/sec just by switching from substring operations to Span slicing. The difference:
- `string.Substring()`: Allocates new string on heap
- `ReadOnlySpan<char>.Slice()`: Zero allocations, zero GC pressure

**`ArrayPool<T>`:** Reusing buffers instead of allocating eliminates GC pressure. In high-throughput systems:
- Without pooling: Gen 2 collections every few seconds, causing 100ms pauses
- With pooling: Gen 2 collections every few minutes, minimal pauses

For a system handling 50K requests/sec, this difference determines whether you can meet SLAs.

**`ValueTask<T>`:** When results are often cached, ValueTask eliminates Task allocations:
- Cache hit with `Task<T>`: Allocates ~96 bytes per call
- Cache hit with `ValueTask<T>`: Zero allocations

In high-frequency caching scenarios, this can eliminate gigabytes of allocations per hour.

**The cost of ignorance:** Common performance mistakes that destroy scalability:

**String concatenation in loops:**
```csharp
// This code causes O(n¬≤) allocations and can slow systems 1000x
for (int i = 0; i < 10000; i++)
    result += i.ToString(); // Allocates new string each iteration!
```

**LINQ in hot paths:**
```csharp
// In a tight loop processing millions of items:
var result = data.Where(x => x.IsActive).Select(x => x.Value).Sum();
// Allocates enumerators, intermediate collections, etc.
```

**Repeated dictionary lookups:**
```csharp
if (dict.ContainsKey(key))
    var value = dict[key]; // Second lookup!
```

These patterns are everywhere in codebases I review. Fixing them often yields 2-10x performance improvements.

**The measurement imperative:** The #1 rule of optimization is "measure, don't guess":
- **Profiling:** Use tools (dotTrace, PerfView) to find actual bottlenecks
- **Benchmarking:** Use BenchmarkDotNet for accurate measurements (not DateTime.Now!)
- **Load testing:** Test under realistic production load
- **Monitoring:** Track performance metrics in production

I've seen developers spend weeks optimizing the wrong thing because they didn't profile first. Always measure.

**Real-world optimization case studies:**

**Case 1 - API optimization:**
- Before: 1,000 req/sec, 200ms p99 latency, 10 servers
- Found: LINQ in request processing, boxing in serialization, synchronous I/O
- After: 10,000 req/sec, 20ms p99 latency, 2 servers
- Result: 10x throughput, 10x latency improvement, 80% cost reduction

**Case 2 - Memory optimization:**
- Before: 8GB memory usage, frequent OutOfMemoryException
- Found: String.Split in hot path, no buffer pooling, memory leaks
- After: 1GB memory usage, stable under load
- Result: Could run on smaller instances, saving $200K/year

**Advanced optimization techniques:**
- **Struct enumerators:** Eliminate LINQ allocation overhead
- **Stack allocation:** Use `stackalloc` for small temporary buffers
- **Aggressive inlining:** `[MethodImpl(MethodImplOptions.AggressiveInlining)]`
- **SIMD:** Vectorization for parallel data processing
- **Unsafe code:** When absolutely necessary for performance

**When NOT to optimize:**
- Code that runs once at startup
- Error handling paths
- Code that's fast enough for requirements
- Before you've profiled and measured

Premature optimization wastes time and makes code harder to maintain.

**Interview expectations:** When interviewers ask about performance, they're evaluating:
- Can you identify performance bottlenecks systematically?
- Do you know modern .NET performance features?
- Can you explain the trade-offs between readable and performant code?
- Do you understand memory allocation and GC impact?
- Can you optimize systems under production load?
- Do you know when to optimize and when not to?
- Can you measure performance scientifically?
- Do you understand algorithmic complexity (Big O)?

Performance optimization questions are common in senior/principal engineer interviews because they require:
- Deep understanding of the runtime
- Profiling and measurement skills
- Architectural thinking about scalability
- Balance between maintainability and performance
- Real production experience with systems under load

This knowledge demonstrates that you can build systems that not only work, but work efficiently at scale‚Äîa critical skill for senior roles where you're architecting systems that need to serve millions of users or process billions of events.

---

## Core Ideas

### 1. **Measure before optimizing**

**Golden rule:** "Premature optimization is the root of all evil."

Always:
1. Profile to find bottlenecks
2. Benchmark before and after
3. Optimize the hot path only
4. Verify improvement with metrics

```csharp
// Use BenchmarkDotNet for accurate measurements
[MemoryDiagnoser]
public class StringConcatBenchmarks
{
    [Benchmark]
    public string StringConcat()
    {
        var result = "";
        for (int i = 0; i < 100; i++)
            result += i.ToString();
        return result;
    }
    
    [Benchmark]
    public string StringBuilder()
    {
        var sb = new StringBuilder();
        for (int i = 0; i < 100; i++)
            sb.Append(i);
        return sb.ToString();
    }
}
```

**Mental model:**  
"Profile ‚Üí Measure ‚Üí Optimize ‚Üí Verify. Never guess."

---

### 2. **Span<T> and Memory<T> reduce allocations**

`Span<T>` is a **ref struct** that provides a view over contiguous memory without allocations.

```csharp
// ‚ùå Allocates substring
string text = "Hello, World!";
string hello = text.Substring(0, 5); // Allocates new string

// ‚úÖ No allocation with Span
ReadOnlySpan<char> span = text.AsSpan();
ReadOnlySpan<char> hello = span.Slice(0, 5); // No allocation!
```

**Benefits:**
- Zero allocations for slicing
- Works with arrays, strings, stack memory
- Safe (bounds-checked)
- High performance

---

### 3. **ValueTask for high-performance async**

Use `ValueTask<T>` instead of `Task<T>` when result is often available synchronously.

```csharp
// ‚ùå Always allocates Task
public async Task<int> GetCachedValueAsync(string key)
{
    if (_cache.TryGetValue(key, out int value))
        return value; // Still allocates Task!
    
    return await FetchFromDbAsync(key);
}

// ‚úÖ No allocation when cached
public async ValueTask<int> GetCachedValueAsync(string key)
{
    if (_cache.TryGetValue(key, out int value))
        return value; // No Task allocation!
    
    return await FetchFromDbAsync(key);
}
```

**Rule:** Use `ValueTask<T>` for hot paths where synchronous completion is common.

---

### 4. **ArrayPool and MemoryPool reduce GC pressure**

Reuse arrays instead of allocating:

```csharp
// ‚ùå Allocates and GC collects every time
public void ProcessData()
{
    byte[] buffer = new byte[4096];
    // Use buffer
} // Buffer is now garbage

// ‚úÖ Rent from pool
public void ProcessData()
{
    var pool = ArrayPool<byte>.Shared;
    byte[] buffer = pool.Rent(4096); // Reuses existing array
    try
    {
        // Use buffer
    }
    finally
    {
        pool.Return(buffer); // Return for reuse
    }
}
```

---

### 5. **Common performance patterns**

| Pattern | Slow | Fast |
|---------|------|------|
| String concatenation | `str += x` | `StringBuilder` |
| LINQ on hot path | `.Where().Select()` | `for` loop |
| Casting | `(Type)obj` repeatedly | Cache cast result |
| Dictionary lookup | Multiple `dict[key]` | `TryGetValue` once |
| Enumeration | `IEnumerable<T>` | `IList<T>` or array |
| Large allocations | `new byte[100000]` | `ArrayPool<byte>.Shared` |
| Async when cached | `Task<T>` | `ValueTask<T>` |
| String operations | `Substring`, `Split` | `Span<T>` |

---

## Examples

### Example 1 ‚Äî Span<T> for string parsing

```csharp
// ‚ùå Allocates many strings
public (string, string) ParseOld(string input)
{
    var parts = input.Split(','); // Allocates array + strings
    return (parts[0].Trim(), parts[1].Trim()); // More allocations
}

// ‚úÖ Zero allocations with Span
public (ReadOnlySpan<char>, ReadOnlySpan<char>) ParseNew(ReadOnlySpan<char> input)
{
    int commaIndex = input.IndexOf(',');
    if (commaIndex == -1)
        return (input, ReadOnlySpan<char>.Empty);
    
    var left = input.Slice(0, commaIndex).Trim();
    var right = input.Slice(commaIndex + 1).Trim();
    return (left, right);
}

// Usage
string data = "Alice, 30";
var (name, age) = ParseNew(data.AsSpan());
// No allocations!
```

---

### Example 2 ‚Äî ValueTask for caching

```csharp
public class CachedDataService
{
    private readonly Dictionary<string, Data> _cache = new();
    private readonly IDataStore _store;
    
    public async ValueTask<Data> GetDataAsync(string key)
    {
        // Check cache - no Task allocation if found
        if (_cache.TryGetValue(key, out var data))
            return data;
        
        // Fetch from store - only allocates when needed
        data = await _store.FetchAsync(key);
        _cache[key] = data;
        return data;
    }
}
```

---

### Example 3 ‚Äî ArrayPool for buffers

```csharp
public class FileProcessor
{
    public async Task ProcessFileAsync(string path)
    {
        var pool = ArrayPool<byte>.Shared;
        byte[] buffer = pool.Rent(4096);
        
        try
        {
            using var stream = File.OpenRead(path);
            int bytesRead;
            while ((bytesRead = await stream.ReadAsync(buffer, 0, buffer.Length)) > 0)
            {
                ProcessChunk(buffer.AsSpan(0, bytesRead));
            }
        }
        finally
        {
            pool.Return(buffer);
        }
    }
    
    private void ProcessChunk(Span<byte> data)
    {
        // Process data
    }
}
```

---

### Example 4 ‚Äî Struct enumerators

```csharp
// ‚ùå LINQ allocates enumerator
var result = numbers.Where(x => x > 5).Select(x => x * 2).ToList();

// ‚úÖ Struct enumerator - no allocation
public struct FilteredEnumerator<T>
{
    private T[] _array;
    private Func<T, bool> _predicate;
    private int _index;
    
    public FilteredEnumerator(T[] array, Func<T, bool> predicate)
    {
        _array = array;
        _predicate = predicate;
        _index = -1;
    }
    
    public T Current => _array[_index];
    
    public bool MoveNext()
    {
        while (++_index < _array.Length)
        {
            if (_predicate(_array[_index]))
                return true;
        }
        return false;
    }
}

// Usage - zero allocations
var numbers = new[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };
var enumerator = new FilteredEnumerator<int>(numbers, x => x > 5);
while (enumerator.MoveNext())
{
    Console.WriteLine(enumerator.Current * 2);
}
```

---

### Example 5 ‚Äî Benchmarking with BenchmarkDotNet

```csharp
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;

[MemoryDiagnoser]
[RankColumn]
public class ParsingBenchmarks
{
    private const string Data = "123,456,789";
    
    [Benchmark(Baseline = true)]
    public int[] ParseWithSplit()
    {
        return Data.Split(',').Select(int.Parse).ToArray();
    }
    
    [Benchmark]
    public int[] ParseWithSpan()
    {
        var result = new int[3];
        var span = Data.AsSpan();
        int resultIndex = 0;
        
        while (!span.IsEmpty)
        {
            int commaIndex = span.IndexOf(',');
            ReadOnlySpan<char> part;
            
            if (commaIndex >= 0)
            {
                part = span.Slice(0, commaIndex);
                span = span.Slice(commaIndex + 1);
            }
            else
            {
                part = span;
                span = ReadOnlySpan<char>.Empty;
            }
            
            result[resultIndex++] = int.Parse(part);
        }
        
        return result;
    }
}

// Run benchmarks
class Program
{
    static void Main(string[] args)
    {
        BenchmarkRunner.Run<ParsingBenchmarks>();
    }
}

// Results:
// |           Method |     Mean | Allocated |
// |----------------- |---------:|----------:|
// |  ParseWithSplit | 450.0 ns |     584 B |
// |   ParseWithSpan | 120.0 ns |      72 B |
```

---

### Example 6 ‚Äî Avoiding closure allocations

```csharp
// ‚ùå Captures 'multiplier' - allocates closure
public List<Func<int, int>> CreateMultipliersOld(int multiplier)
{
    var funcs = new List<Func<int, int>>();
    for (int i = 0; i < 10; i++)
    {
        funcs.Add(x => x * multiplier); // Closure allocation
    }
    return funcs;
}

// ‚úÖ Pass state explicitly - no closure
public List<Multiplier> CreateMultipliersNew(int multiplier)
{
    var funcs = new List<Multiplier>();
    for (int i = 0; i < 10; i++)
    {
        funcs.Add(new Multiplier(multiplier)); // Struct, no heap allocation
    }
    return funcs;
}

public readonly struct Multiplier
{
    private readonly int _multiplier;
    
    public Multiplier(int multiplier)
    {
        _multiplier = multiplier;
    }
    
    public int Apply(int value) => value * _multiplier;
}
```

---

## Common Pitfalls

### ‚ùå Pitfall 1: String concatenation in loops

```csharp
// ‚ùå O(n¬≤) complexity - allocates new string each iteration
string result = "";
for (int i = 0; i < 1000; i++)
{
    result += i.ToString(); // Terrible!
}

// ‚úÖ O(n) with StringBuilder
var sb = new StringBuilder();
for (int i = 0; i < 1000; i++)
{
    sb.Append(i);
}
string result = sb.ToString();
```

---

### ‚ùå Pitfall 2: LINQ on hot path

```csharp
// ‚ùå Allocates enumerators, iterators
public int ProcessData(List<int> numbers)
{
    return numbers
        .Where(x => x > 0)
        .Select(x => x * 2)
        .Sum();
}

// ‚úÖ Direct loop - zero allocations
public int ProcessData(List<int> numbers)
{
    int sum = 0;
    for (int i = 0; i < numbers.Count; i++)
    {
        int n = numbers[i];
        if (n > 0)
            sum += n * 2;
    }
    return sum;
}
```

---

### ‚ùå Pitfall 3: Boxing value types

```csharp
// ‚ùå Boxing on every comparison
ArrayList list = new ArrayList { 1, 2, 3, 4, 5 };
foreach (object item in list) // Boxing
{
    Console.WriteLine(item); // Boxing
}

// ‚úÖ Generic collection - no boxing
List<int> list = new List<int> { 1, 2, 3, 4, 5 };
foreach (int item in list) // No boxing
{
    Console.WriteLine(item);
}
```

---

### ‚ùå Pitfall 4: Repeated Dictionary lookups

```csharp
// ‚ùå Looks up twice
if (dict.ContainsKey(key))
{
    var value = dict[key]; // Second lookup!
}

// ‚úÖ Single lookup
if (dict.TryGetValue(key, out var value))
{
    // Use value
}
```

---

### ‚ùå Pitfall 5: Large allocations without pooling

```csharp
// ‚ùå Allocates 1MB each time - LOH pressure
public void ProcessRequests()
{
    for (int i = 0; i < 1000; i++)
    {
        byte[] buffer = new byte[1_000_000]; // 1 MB
        // Process
    } // GC collects 1000 MB!
}

// ‚úÖ Rent from pool
public void ProcessRequests()
{
    var pool = ArrayPool<byte>.Shared;
    for (int i = 0; i < 1000; i++)
    {
        byte[] buffer = pool.Rent(1_000_000);
        try
        {
            // Process
        }
        finally
        {
            pool.Return(buffer);
        }
    }
}
```

---

## Quick Self-Check

1. What's the first step before optimizing code?
2. What are `Span<T>` and `Memory<T>` used for?
3. When should you use `ValueTask<T>` instead of `Task<T>`?
4. What's the performance difference between `StringBuilder` and `+=`?
5. How do you avoid allocations with large buffers?

<details>
<summary>Answers</summary>

1. Profile to identify bottlenecks, then benchmark to establish baseline
2. Zero-allocation views over contiguous memory (arrays, strings, stack)
3. When synchronous completion is common (e.g., cached results)
4. `StringBuilder` is O(n), `+=` is O(n¬≤) due to repeated allocations
5. Use `ArrayPool<T>.Shared` to rent and return buffers

</details>

---

## Further Practice

1. **Benchmark** string concatenation vs `StringBuilder` vs `String.Concat` vs interpolation
2. **Refactor** a LINQ query to use `Span<T>` and measure improvement
3. **Profile** an application with dotTrace or PerfView
4. **Implement** a zero-allocation JSON parser for simple formats
5. **Optimize** a hot path method reducing allocations by 90%

---

## Performance Optimization Checklist

When optimizing code:

‚úÖ **Profile first** - Use profiler to find bottlenecks  
‚úÖ **Benchmark** - Use BenchmarkDotNet for accurate measurements  
‚úÖ **Reduce allocations** - Use `Span<T>`, `ArrayPool<T>`, structs  
‚úÖ **Avoid LINQ on hot path** - Use direct loops  
‚úÖ **Cache expensive operations** - Type lookups, regex, config  
‚úÖ **Use `StringBuilder`** - For repeated string concatenation  
‚úÖ **Single dictionary lookup** - Use `TryGetValue` not `ContainsKey` + indexer  
‚úÖ **ValueTask for async** - When synchronous completion is common  
‚úÖ **Struct enumerators** - Custom iterators without allocation  
‚úÖ **Avoid boxing** - Use generic collections and methods

---

## Key Takeaways

‚úÖ Always profile before optimizing  
‚úÖ `Span<T>` for zero-allocation slicing and parsing  
‚úÖ `ValueTask<T>` when result often available synchronously  
‚úÖ `ArrayPool<T>` for large temporary buffers  
‚úÖ Avoid string concatenation in loops - use `StringBuilder`  
‚úÖ Direct loops faster than LINQ on hot paths  
‚úÖ Single `TryGetValue` better than `ContainsKey` + indexer  
‚úÖ BenchmarkDotNet for accurate performance measurements  
‚úÖ Struct types avoid heap allocations  
‚úÖ Generic collections prevent boxing
