# Testing & Testability

**Level:** üö¶ Intermediate  
**Tags:** `testing`, `unit-tests`, `TDD`, `mocking`, `xUnit`, `NUnit`, `integration-tests`, `interview`

---

## Why this matters

Testing is where theory meets practice‚Äîthe difference between code that "works on my machine" and code that's proven correct, maintainable, and deployable with confidence. Yet testing is paradoxically both universally acknowledged as important and chronically underinvested in. Understanding testing deeply‚Äîunit tests, integration tests, mocking, TDD‚Äîseparates professional engineers who ship reliable systems from those who hope their code works.

**Untested code is legacy code from day one.** I've inherited codebases with 0% test coverage where every change was terrifying. Touch one method, break three others. Deploy a "simple fix," crash production. Teams spend more time manually testing and firefighting bugs than they would have spent writing automated tests. One team's "quick feature" took 6 weeks because manual regression testing found new bugs with every iteration. After adding tests (70% coverage), similar features took days instead of weeks. Testing isn't overhead‚Äîit's the foundation of velocity.

**Interviews heavily emphasize testing because it's a forcing function for good design.** When an interviewer asks "How would you test this code?" they're really asking: Can you write testable code? Do you understand dependency inversion? Can you separate concerns? Code that's hard to test is usually poorly designed‚Äîtight coupling, hidden dependencies, violation of SOLID principles. I've seen candidates write algorithmically correct code that was impossible to test because it used static dependencies, hardcoded file paths, and direct database access. Testing skill is a proxy for design skill.

**Test-Driven Development (TDD) is controversial but transformational when understood.** Write test first, watch it fail, write minimal code to pass, refactor‚Äî"red, green, refactor." Skeptics dismiss it as dogma, but I've seen TDD turn ambiguous requirements into concrete specifications, catch design flaws before implementation, and create living documentation. One team adopted TDD for a complex pricing engine and found bugs in requirements during test writing, before any implementation. The final code had 95% coverage, clear contracts, and no production bugs in 18 months. TDD isn't about testing‚Äîit's about design and specification.

**Mocking is simultaneously essential and dangerous.** Mocking frameworks (Moq, NSubstitute) let you isolate units by faking dependencies, enabling true unit tests. But I've reviewed test suites with excessive mocking that tested implementation details rather than behavior, breaking whenever code was refactored (even if behavior stayed correct). Or tests that mocked so much they had no confidence value‚Äîpassing tests but production failures. Understanding when to mock (external dependencies, slow operations) versus when to use real implementations (value objects, simple logic) is a nuanced skill. Over-mocking is as bad as under-testing.

**Test pyramid (unit > integration > E2E) guides efficient testing strategies.** Unit tests are fast, isolated, and plentiful (70-80% of tests). Integration tests verify components work together (15-20%). End-to-end tests verify full workflows (5-10%). I've seen teams invert this‚Äîmostly slow E2E tests, few unit tests‚Äîresulting in 2-hour test runs that broke constantly. Fast feedback requires fast tests. The ability to explain test pyramid and apply it shows architectural understanding beyond just writing tests.

**Code coverage metrics are both useful and misleading.** 100% coverage doesn't guarantee quality‚Äîyou can test every line without testing actual behavior. But 20% coverage definitely indicates untested code. I've seen teams game metrics (tests that run code but don't assert anything) versus teams that use coverage to identify gaps. Understanding that coverage measures "executed lines" not "verified behavior" shows maturity. Interviews probe whether you treat coverage as a goal (bad) or a tool (good).

**Integration tests catch real-world failures unit tests miss.** Unit tests verify individual components, but systems fail at boundaries‚Äîdatabase serialization, network timeouts, configuration issues, version conflicts. I've seen production bugs where every unit test passed but integration tests would have caught: wrong SQL generated by ORM, JSON serialization failing for specific values, deadlocks in actual database transactions. Integration tests are slower but essential. Knowing when you need them demonstrates systems thinking.

**Flaky tests are worse than no tests.** Tests that pass sometimes, fail other times (race conditions, timing dependencies, external dependencies) erode confidence until teams ignore test failures. I've seen CI/CD pipelines where test failures were routine ("just retry"), defeating the purpose of tests. One team spent 6 months recovering from flaky test culture by isolating tests, removing timing dependencies, and using test containers. Flakiness indicates poor test design‚Äîusually shared state, external dependencies, or concurrency bugs.

**Testability drives architectural decisions.** Dependency injection exists primarily to enable testing. Interfaces abstract dependencies for mocking. Pure functions (no side effects) are trivially testable. I've refactored systems to improve testability and found the designs improved universally‚Äîclearer boundaries, better separation of concerns, easier to understand. When you design for testability, you get better architecture. This is why testing questions appear in architecture interviews‚Äîthey're inseparable.

**Production bugs correlate inversely with test quality.** Not quantity‚Äîquality. I've tracked teams' production bug rates before and after adopting rigorous testing: 80% reduction in customer-reported bugs, 60% reduction in hotfixes, 40% faster feature delivery (less time debugging). The ROI of testing is measurable and significant. Conversely, teams skipping tests accumulate technical debt that eventually paralyzes development. Understanding testing's business value, not just technical value, positions you for leadership roles.

**Career impact is substantial.** Senior engineers are expected to write testable code and guide teams on testing strategies. Staff+ engineers define testing policies, improve test infrastructure, and mentor on test quality. Companies increasingly require test-driven development skills. When you can demonstrate test-driven design, explain testing tradeoffs, and build confidence through comprehensive testing, you're operating at a professional level that commands respect and compensation.

---

## Core Ideas

### 1. **Unit Tests: Testing in Isolation**

**Unit test** verifies a single unit (method, class) in isolation from dependencies.

**Characteristics:**
- **Fast** ‚Äî milliseconds
- **Isolated** ‚Äî no database, network, file system
- **Repeatable** ‚Äî same result every time
- **Self-validating** ‚Äî clear pass/fail

```csharp
// Unit under test
public class Calculator
{
    public int Add(int a, int b) => a + b;
}

// Unit test (xUnit)
public class CalculatorTests
{
    [Fact]
    public void Add_TwoPositiveNumbers_ReturnsSum()
    {
        // Arrange
        var calculator = new Calculator();
        
        // Act
        var result = calculator.Add(2, 3);
        
        // Assert
        Assert.Equal(5, result);
    }
}
```

**AAA Pattern:**
- **Arrange** ‚Äî set up test data and dependencies
- **Act** ‚Äî execute the unit under test
- **Assert** ‚Äî verify the result

---

### 2. **Test Frameworks: xUnit, NUnit, MSTest**

**xUnit (Modern, Recommended):**
```csharp
[Fact]  // Simple test
public void Test_Something()
{
    Assert.True(true);
}

[Theory]  // Parameterized test
[InlineData(2, 3, 5)]
[InlineData(0, 0, 0)]
[InlineData(-1, 1, 0)]
public void Add_VariousInputs_ReturnsCorrectSum(int a, int b, int expected)
{
    var result = new Calculator().Add(a, b);
    Assert.Equal(expected, result);
}
```

**NUnit:**
```csharp
[Test]
public void Test_Something()
{
    Assert.That(true, Is.True);
}

[TestCase(2, 3, 5)]
[TestCase(0, 0, 0)]
public void Add_VariousInputs_ReturnsCorrectSum(int a, int b, int expected)
{
    var result = new Calculator().Add(a, b);
    Assert.That(result, Is.EqualTo(expected));
}
```

**Common assertions:**
```csharp
// xUnit
Assert.Equal(expected, actual);
Assert.NotEqual(expected, actual);
Assert.True(condition);
Assert.False(condition);
Assert.Null(obj);
Assert.NotNull(obj);
Assert.Throws<Exception>(() => method());
Assert.Contains(item, collection);

// NUnit
Assert.That(actual, Is.EqualTo(expected));
Assert.That(condition, Is.True);
Assert.That(obj, Is.Null);
Assert.That(() => method(), Throws.Exception);
```

---

### 3. **Mocking: Isolating Dependencies**

**Why mock:**
- External dependencies (database, API, file system)
- Slow operations
- Non-deterministic behavior
- Test error conditions

**Moq (Popular Mocking Framework):**
```csharp
// Interface to mock
public interface IEmailService
{
    Task SendEmail(string to, string subject, string body);
}

// Class under test
public class UserService
{
    private readonly IEmailService _emailService;
    
    public UserService(IEmailService emailService)
    {
        _emailService = emailService;
    }
    
    public async Task RegisterUser(string email)
    {
        // Registration logic...
        
        await _emailService.SendEmail(email, "Welcome", "Thanks for registering");
    }
}

// Unit test with mock
[Fact]
public async Task RegisterUser_CallsEmailService()
{
    // Arrange
    var mockEmailService = new Mock<IEmailService>();
    var userService = new UserService(mockEmailService.Object);
    
    // Act
    await userService.RegisterUser("test@example.com");
    
    // Assert
    mockEmailService.Verify(
        m => m.SendEmail("test@example.com", "Welcome", "Thanks for registering"),
        Times.Once);
}
```

**Setting up mock behavior:**
```csharp
var mock = new Mock<IDataService>();

// Return value
mock.Setup(m => m.GetData(It.IsAny<int>()))
    .Returns("test data");

// Return different values
mock.Setup(m => m.GetData(1)).Returns("data 1");
mock.Setup(m => m.GetData(2)).Returns("data 2");

// Throw exception
mock.Setup(m => m.GetData(It.IsAny<int>()))
    .Throws<InvalidOperationException>();

// Async method
mock.Setup(m => m.GetDataAsync(It.IsAny<int>()))
    .ReturnsAsync("async data");
```

---

### 4. **Test-Driven Development (TDD)**

**TDD Cycle:**
1. **Red** ‚Äî Write a failing test
2. **Green** ‚Äî Write minimal code to pass the test
3. **Refactor** ‚Äî Improve code while keeping tests green

**Example: Building a StringCalculator**

```csharp
// Step 1: RED - Write failing test
[Fact]
public void Add_EmptyString_ReturnsZero()
{
    var calculator = new StringCalculator();
    var result = calculator.Add("");
    Assert.Equal(0, result);
}
// Test fails because StringCalculator doesn't exist

// Step 2: GREEN - Minimal implementation
public class StringCalculator
{
    public int Add(string numbers)
    {
        return 0;  // Minimal code to pass
    }
}
// Test passes

// Step 3: Add next test (RED)
[Fact]
public void Add_SingleNumber_ReturnsNumber()
{
    var calculator = new StringCalculator();
    var result = calculator.Add("5");
    Assert.Equal(5, result);
}

// Step 4: Update implementation (GREEN)
public int Add(string numbers)
{
    if (string.IsNullOrEmpty(numbers)) return 0;
    return int.Parse(numbers);
}

// Step 5: Add next test (RED)
[Fact]
public void Add_TwoNumbers_ReturnsSum()
{
    var calculator = new StringCalculator();
    var result = calculator.Add("2,3");
    Assert.Equal(5, result);
}

// Step 6: Update implementation (GREEN)
public int Add(string numbers)
{
    if (string.IsNullOrEmpty(numbers)) return 0;
    
    var parts = numbers.Split(',');
    if (parts.Length == 1) return int.Parse(parts[0]);
    
    return parts.Sum(int.Parse);
}

// Step 7: REFACTOR (tests stay green)
public int Add(string numbers)
{
    if (string.IsNullOrEmpty(numbers)) return 0;
    return numbers.Split(',').Sum(int.Parse);
}
```

**TDD Benefits:**
- Requirements become concrete specifications
- Design emerges from tests
- High confidence (every line has a test)
- Living documentation

---

### 5. **Integration Tests: Testing Boundaries**

**Integration test** verifies multiple components work together.

```csharp
public class OrderRepositoryIntegrationTests : IDisposable
{
    private readonly SqlConnection _connection;
    
    public OrderRepositoryIntegrationTests()
    {
        // Set up test database
        _connection = new SqlConnection("test-connection-string");
        _connection.Open();
        SetupTestSchema();
    }
    
    [Fact]
    public async Task SaveOrder_PersistsToDatabase()
    {
        // Arrange
        var repository = new OrderRepository(_connection);
        var order = new Order { CustomerId = "123", Total = 99.99m };
        
        // Act
        await repository.SaveAsync(order);
        
        // Assert
        var saved = await repository.GetByIdAsync(order.Id);
        Assert.NotNull(saved);
        Assert.Equal(order.CustomerId, saved.CustomerId);
        Assert.Equal(order.Total, saved.Total);
    }
    
    public void Dispose()
    {
        _connection?.Dispose();
    }
}
```

**Integration test characteristics:**
- Slower than unit tests (seconds vs milliseconds)
- Use real dependencies (database, message queue, etc.)
- Test interactions and data flow
- May require setup/teardown

**Test containers (Testcontainers):**
```csharp
public class DatabaseIntegrationTests : IAsyncLifetime
{
    private SqlServerContainer _container;
    
    public async Task InitializeAsync()
    {
        // Start SQL Server container
        _container = new SqlServerBuilder().Build();
        await _container.StartAsync();
    }
    
    [Fact]
    public async Task Test_WithRealDatabase()
    {
        var connectionString = _container.GetConnectionString();
        // Use real SQL Server running in Docker
    }
    
    public async Task DisposeAsync()
    {
        await _container.DisposeAsync();
    }
}
```

---

### 6. **Test Doubles: Mocks, Stubs, Fakes**

**Stub** ‚Äî Returns hardcoded responses
```csharp
public class StubEmailService : IEmailService
{
    public Task SendEmail(string to, string subject, string body)
    {
        return Task.CompletedTask;  // Do nothing
    }
}
```

**Mock** ‚Äî Verifies interactions
```csharp
var mock = new Mock<IEmailService>();
// ... test code ...
mock.Verify(m => m.SendEmail(...), Times.Once);
```

**Fake** ‚Äî Simplified working implementation
```csharp
public class InMemoryUserRepository : IUserRepository
{
    private readonly List<User> _users = new();
    
    public Task<User> GetByIdAsync(int id)
    {
        return Task.FromResult(_users.FirstOrDefault(u => u.Id == id));
    }
    
    public Task SaveAsync(User user)
    {
        _users.Add(user);
        return Task.CompletedTask;
    }
}
```

---

### 7. **Test Naming Conventions**

**Good test names describe behavior:**

```csharp
// ‚úÖ GOOD: Descriptive
[Fact]
public void Add_TwoPositiveNumbers_ReturnsSum()

[Fact]
public void Withdraw_InsufficientFunds_ThrowsException()

[Fact]
public void ProcessOrder_InvalidOrder_ReturnsFalse()

// ‚ùå BAD: Not descriptive
[Fact]
public void Test1()

[Fact]
public void TestAdd()
```

**Common patterns:**
- `MethodName_Scenario_ExpectedBehavior`
- `Given_When_Then` (BDD style)
- `Should_ExpectedBehavior_When_Scenario`

---

### 8. **Code Coverage: Useful Tool, Not a Goal**

**What coverage measures:**
- Percentage of code lines executed by tests
- Doesn't measure quality or correctness

```bash
# Generate coverage report (coverlet + ReportGenerator)
dotnet test /p:CollectCoverage=true /p:CoverletOutputFormat=cobertura
reportgenerator -reports:coverage.cobertura.xml -targetdir:coveragereport
```

**Interpreting coverage:**
- **< 50%** ‚Äî Significant gaps, high risk
- **50-70%** ‚Äî Moderate coverage
- **70-85%** ‚Äî Good coverage
- **> 85%** ‚Äî Excellent coverage
- **100%** ‚Äî Possibly over-testing or gaming metrics

**Coverage ‚â† Quality:**
```csharp
// ‚ùå 100% coverage but useless test
[Fact]
public void Add_Test()
{
    var result = calculator.Add(2, 3);
    // No assertion! Test passes but verifies nothing
}
```

---

## Examples

### Example 1 ‚Äî Unit test with dependency injection

```csharp
public class OrderService
{
    private readonly IOrderRepository _repository;
    private readonly IEmailService _emailService;
    
    public OrderService(IOrderRepository repository, IEmailService emailService)
    {
        _repository = repository;
        _emailService = emailService;
    }
    
    public async Task<bool> ProcessOrder(Order order)
    {
        if (order.Total <= 0) return false;
        
        await _repository.SaveAsync(order);
        await _emailService.SendEmail(order.CustomerEmail, "Order Confirmed", "Thanks!");
        
        return true;
    }
}

// Unit test
public class OrderServiceTests
{
    [Fact]
    public async Task ProcessOrder_ValidOrder_SavesAndSendsEmail()
    {
        // Arrange
        var mockRepository = new Mock<IOrderRepository>();
        var mockEmailService = new Mock<IEmailService>();
        var service = new OrderService(mockRepository.Object, mockEmailService.Object);
        
        var order = new Order { Total = 100, CustomerEmail = "test@example.com" };
        
        // Act
        var result = await service.ProcessOrder(order);
        
        // Assert
        Assert.True(result);
        mockRepository.Verify(r => r.SaveAsync(order), Times.Once);
        mockEmailService.Verify(
            e => e.SendEmail("test@example.com", "Order Confirmed", "Thanks!"),
            Times.Once);
    }
    
    [Fact]
    public async Task ProcessOrder_InvalidTotal_ReturnsFalse()
    {
        // Arrange
        var mockRepository = new Mock<IOrderRepository>();
        var mockEmailService = new Mock<IEmailService>();
        var service = new OrderService(mockRepository.Object, mockEmailService.Object);
        
        var order = new Order { Total = 0 };
        
        // Act
        var result = await service.ProcessOrder(order);
        
        // Assert
        Assert.False(result);
        mockRepository.Verify(r => r.SaveAsync(It.IsAny<Order>()), Times.Never);
    }
}
```

---

### Example 2 ‚Äî Testing exceptions

```csharp
[Fact]
public void Withdraw_InsufficientFunds_ThrowsException()
{
    // Arrange
    var account = new BankAccount(balance: 100);
    
    // Act & Assert
    var exception = Assert.Throws<InvalidOperationException>(() => 
        account.Withdraw(200));
    
    Assert.Equal("Insufficient funds", exception.Message);
}

[Fact]
public async Task GetUser_NotFound_ThrowsNotFoundException()
{
    var mockRepo = new Mock<IUserRepository>();
    mockRepo.Setup(r => r.GetByIdAsync(It.IsAny<int>()))
            .ThrowsAsync(new NotFoundException());
    
    var service = new UserService(mockRepo.Object);
    
    await Assert.ThrowsAsync<NotFoundException>(() => 
        service.GetUserAsync(999));
}
```

---

## Common Pitfalls

### ‚ùå 1. Testing implementation details

```csharp
// ‚ùå BAD: Tests internal implementation
[Fact]
public void ProcessOrder_CallsValidateMethodOnce()
{
    mock.Verify(m => m.ValidateInternal(), Times.Once);  // Implementation detail!
}

// ‚úÖ GOOD: Tests behavior
[Fact]
public void ProcessOrder_InvalidOrder_ReturnsError()
{
    var result = service.ProcessOrder(invalidOrder);
    Assert.False(result.IsSuccess);
}
```

---

### ‚ùå 2. Shared state between tests

```csharp
// ‚ùå BAD: Tests interfere with each other
public class OrderServiceTests
{
    private static List<Order> _orders = new();  // Shared!
    
    [Fact]
    public void Test1() { _orders.Add(new Order()); }
    
    [Fact]
    public void Test2() { Assert.Empty(_orders); }  // Fails if Test1 runs first!
}

// ‚úÖ GOOD: Each test is independent
public class OrderServiceTests
{
    [Fact]
    public void Test1()
    {
        var orders = new List<Order>();  // Local
        orders.Add(new Order());
    }
}
```

---

### ‚ùå 3. Over-mocking

```csharp
// ‚ùå BAD: Mocking value objects and simple logic
var mockDateTime = new Mock<IDateTime>();
var mockString = new Mock<IStringHelper>();
var mockValidator = new Mock<IValidator>();

// ‚úÖ GOOD: Only mock external dependencies
var mockDatabase = new Mock<IDatabase>();
var mockEmailService = new Mock<IEmailService>();
```

---

## Quick Self-Check

You should be able to answer these out loud:

1. What's the difference between unit, integration, and E2E tests?
2. What's the AAA pattern in testing?
3. When should you use mocking vs real implementations?
4. What's TDD and what are its benefits?
5. What does code coverage measure and what doesn't it measure?
6. What's the difference between a mock, stub, and fake?
7. Why is shared state between tests problematic?
8. How do you test async methods?

If you struggle with any of these, revisit the relevant section.

---

## Further Practice

1. Write unit tests for a calculator class (TDD style).
2. Refactor untestable code to be testable using dependency injection.
3. Write integration tests for a database repository.
4. Use Moq to mock a complex interface with multiple methods.
5. Measure code coverage and identify untested branches.

---

## Mini Interview Cheat Sheet

**Explain testing pyramid in 30 seconds:**
"Most tests should be fast unit tests (70-80%), fewer integration tests (15-20%), and minimal E2E tests (5-10%). Fast feedback requires fast tests. Unit tests verify components in isolation, integration tests verify boundaries, E2E tests verify full workflows."

**TDD in brief:**
"Red-Green-Refactor: Write failing test, write minimal code to pass, refactor while keeping tests green. Benefits: tests become specifications, drives better design, high confidence."

**When to mock:**
- ‚úÖ External dependencies (DB, API, file system)
- ‚úÖ Slow operations
- ‚úÖ Non-deterministic behavior
- ‚ùå Value objects, simple logic, DTOs

**AAA Pattern:**
- **Arrange** ‚Äî setup test data
- **Act** ‚Äî execute unit under test
- **Assert** ‚Äî verify result

**Test naming:**
`MethodName_Scenario_ExpectedBehavior`

---
